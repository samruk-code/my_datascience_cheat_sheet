{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25a9ff0-719d-432c-b602-5eff63611a87",
   "metadata": {},
   "source": [
    "# Introduction to Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0169d-f062-49b9-8005-8e4b72fb67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading text file \n",
    "file_name = \"file_name.txt\" # saving file name as a variable\n",
    "file = open(file_name, mode = \"r\") # reading the file name with open function\n",
    "text = file.read() # getting the content in the file and saving it to text variable\n",
    "file.close() # closing the file connection \n",
    "print(text) # printing contents in the file\n",
    "print(file.closed) # chekking wether file connection closed or not \n",
    "file.readline() # reading a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cfb8b-1a7f-42c5-8fc7-0e3879137433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing contents to a text file\n",
    "file_name = \"file_name.txt\"\n",
    "file = open(filename, mode = \"w\") # use the \"w\" to write contnts to a text file \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6360987-868d-4591-9e06-31b2c0b0d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file_name.txt\", \"r\") as file: # read the file and assign all the contents in the file to the file vatiable\n",
    "    print(file.read())               # if you used a with statement you do not need to colse the connection it closes itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5262bba6-a09a-4817-b10b-f3c6916afae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing flate files using NumPy\n",
    "import numpy as np\n",
    "file_name = \"file_name.txt\"\n",
    "data = np.loadtxt(file_name, # name of the file\n",
    "                  delimiter = \",\", # delimiter used to seperate the columns\n",
    "                  skiprows = 1, # number of rows to skip\n",
    "                  usecols = [0,2], # the columns want to import \n",
    "                  dtype = str # data type want to import\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa68e9-7887-4dc8-9846-e22e9ce4a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.recfromcsv(file) # importing mixed data type defult data type is none\n",
    "data = np.genfromtxt(file) # importing mixed data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72812602-e012-49f0-8f45-a511045b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to import data \n",
    "import pandas as pd\n",
    "file_name = \"file_name.txt\" # saving file name as a csv\n",
    "data = pd.read_csv(file_name) # read it by read_csv method \n",
    "data.head() # print the first five rows \n",
    "dataframe.values # return all the rows of datafame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47668699-4742-48ae-885e-3a08e46f87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pickled files\n",
    "import pickle # importing pickle library \n",
    "with open(\"file_name.pkl\", \"rb\") as file: # \"rb\" read and binary\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7110033-55ea-4df1-a0cf-f341a0ef4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing excel file\n",
    "import pandas as pd\n",
    "file_name = \"file_name.xlsx\"\n",
    "data = pd.ExcelFile(file_name) # reading excel file using pandas library \n",
    "print(data.sheet_names) # printing all the sheets names\n",
    "dataframe = data.parse(\"sheet_name\") # selecting sheet by string name\n",
    "dataframe = data.parse(0) # selecting sheet by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b12770-16da-40c4-a9cb-54d24c7ee65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"url_of_the_excel_file\"\n",
    "xls = pd.read_excel(url, sheet_name = None) # reading excel file directly \n",
    "xls.keys() # getting sheet names\n",
    "dataframe = xls.parse(0, # sheet number_index\n",
    "                     skiprows = [0], # number of rows to skip\n",
    "                     names = [\"name\",\"name\"], # name of the columns\n",
    "                     usecols = [0]) # column parsing number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb54a312-35e1-4756-b366-61d068a581f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing SAS file\n",
    "import pandas as pd\n",
    "from sas7bdat import SAS7BDAT # importing necessary functions to lead the data \n",
    "with SAS7BDAT(\"file_name\") as file: # importing file and saving to a variable \n",
    "    dataframe = file.to_data_frame() # saving all the contents to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6fcd8-3df3-4307-b4e8-960f4279162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Stata files\n",
    "dataframe = pd.read_stata(\"file_name.dta\") # pandas function for reading stata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0a56a-4cdb-400e-b95c-057b0f93a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py # importing necassary function for reading HDF5 files\n",
    "file_name = \"file_name.hdf5\" # saving file as a variable\n",
    "data = h5py.File(file_name, \"r\") # reading file  \n",
    "print(type(data)) # chechking type of the file \n",
    "# Hdf file are like multi-level dictionary so we can access all the data by subsetting like subsetting dictionary using key\n",
    "# np.array function used to get the data as a numpy n-diamentional array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d0d3c5-f2a5-4d51-9ed4-7b3a9506b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing matlab data\n",
    "import scipy.io # importing necessary function for leading data \n",
    "file_name = \"file_name.mat\" \n",
    "mat_file = scipy.io.loadmat(file_name) # loading data \n",
    "print(type(mat)) # dictionary file type keys are variable values are object assigned to variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc9e6c-1c43-4320-95df-1b6ccef79cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data from relational database\n",
    "from sqlalchemy import create_engine # importing fuction for get the data\n",
    "engine = create_engine(\"connecter_link\") # creating engine for connecting to sql database\n",
    "print(table_names) # lokking into tables\n",
    "connect = engine.connect() # connecting python to database\n",
    "result = connect.execute(\"SELECT * FROM table_name\") # query from database\n",
    "dataframe = pd.DataFrame(result.fetchall()) # get the data from database and save it to dataframe\n",
    "dataframe.columns = result.keys() # get the datable name and set it as column name in dataframe\n",
    "connect.close() # close the connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3367842-f23a-4960-8078-d96931ea0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine(\"connection_name\")\n",
    "\n",
    "with engine.connect() as connect: # using the context manager\n",
    "    result = connect.execute(\"SELECT * FROM table_name\")\n",
    "    dataframe = pd.DataFrame(result.fetchmany(size = 5)) # using fetchmany to define a limit\n",
    "    dataframe.columns = result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34985c-3abb-4ee5-b7b2-8ad5258e2597",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_sql_query(\"SELECT * FROM table_name\", engine) # reading data and creating dataframe\n",
    "dataframe = pd.read_sql_query(\"SELECT * FROM table_name_0 INNER JOIN table_name_1 ON table_name_0.id = table_name_1.id\", engine) # with joined table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd5296b-1784-4f96-b210-64c44c612f15",
   "metadata": {},
   "source": [
    "# Intermediate Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bc5ca-ad33-498c-9a20-bd3fb7c53297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatting the file download \n",
    "from urllib.request import urlretrieve # importing necessary file for requesting data\n",
    "url = \"url_of_the_file\" # url of the file\n",
    "urlretrieve(url, \"file_name\") # getting data saving to the local drive then reading data by pandas functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7aab3d-396d-45b1-988a-d5ca44351e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"url_of_the_file\"\n",
    "dataframe = pd.read_csv(url, sep = \",\") # reading directly by pandas method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7dad6-5d29-4df9-8570-1610522acc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET requests using urllib\n",
    "from urllib.request import urlopen, Request # importing necessary file for requesting data\n",
    "url = \"url_of_the_file\" # url of the file\n",
    "request = Request(url) # sending the request\n",
    "response = urlopen(request) # getting the response \n",
    "html = response.read() # saving the response as a html file\n",
    "response.close() # closing the connection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe954bf-696d-4d10-bddf-1b20fc409650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "import requests # importing necessary function for the requesting data\n",
    "url = \"url_of_the_resource\"\n",
    "request = requests.get(url) # get the data\n",
    "text = request.text # saving it as a text variable, str file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6df8fe-0180-46d3-9639-1d3cf447f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing HTML files\n",
    "from bs4 import BeautifulSoup \n",
    "import requests \n",
    "url = \"name_of_the_resouces\"\n",
    "request = requests.get(url) # reqesting data\n",
    "html = requests.text # save response as a html variable\n",
    "soup = BeautifulSoup(html) # from html file workable with python through BeautifulSoup library\n",
    "print(soup.prettify()) # make easy for reading \n",
    "soup.title # get the titlte of the page\n",
    "soup.get_text() # get the texts of the page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1aa25-5cfd-460d-8005-9780d98a67ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading JSON \n",
    "import json # importing json library\n",
    "with open(\"file_name.json\", \"r\") as json_file: # connecting and reading json data\n",
    "    json_data = json.load(json_file) # dictionary file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6bdc8-1109-4b96-9272-2b9e293349dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to a API\n",
    "import = requests \n",
    "url = \"url_of_the_resources\" # reating json  data by API\n",
    "response requests.get(url)\n",
    "json_data = response.json() # parse the response as the dictionary by using json method\n",
    "\n",
    "for key, value in json_data.item(): # iterate over the keys and values\n",
    "    print(key + \":\" + value) # printing keys and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73253a-75aa-4101-8513-deccfedef5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing twitter data\n",
    "import tweepy, josn # importing necessary file\n",
    "access_token = \"\" # from twitter documentation \n",
    "access_token_secret = \"\" # from twitter documentation \n",
    "consumer_key = \"\" # from twitter documentation \n",
    "consumer_secret = \"\" # from twitter documentation \n",
    "stream = tweepy.stream(consumer_key, consumer_secret, access_token, access_token_secret) # streeming_data\n",
    "stream.filter(track = [\"string\",\"string\"]) # filtering data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
